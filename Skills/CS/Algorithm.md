---
title: 数据结构和算法
date: 2018-11-21 10:56:52
tags: 
categories: 
    - 算法
---

**目录 start**
 
1. [数据结构和算法](#数据结构和算法)
    1. [相关书籍和资源](#相关书籍和资源)
    1. [基础概念](#基础概念)
        1. [时间复杂度](#时间复杂度)
            1. [时间复杂度分析](#时间复杂度分析)
            1. [最好最坏时间复杂度](#最好最坏时间复杂度)
            1. [平均时间复杂度](#平均时间复杂度)
            1. [均摊时间复杂度](#均摊时间复杂度)
        1. [空间复杂度](#空间复杂度)
    1. [基础数据结构](#基础数据结构)
        1. [线性表](#线性表)
            1. [数组](#数组)
            1. [链表](#链表)
    1. [匹配算法](#匹配算法)
    1. [排序算法](#排序算法)
1. [密码学](#密码学)
    1. [Diffie-Hellman Key Exchange算法](#diffie-hellman-key-exchange算法)
1. [实际问题](#实际问题)

**目录 end**|_2019-01-10 00:10_| [码云](https://gitee.com/gin9) | [CSDN](http://blog.csdn.net/kcp606) | [OSChina](https://my.oschina.net/kcp1104) | [cnblogs](http://www.cnblogs.com/kuangcp)
****************************************
# 数据结构和算法
> 数据结构是指一组数据的存储结构 算法就是操作数据的方法 数据结构和算法是相辅相成的，数据结构是为算法服务的，而算法要作用在特定的数据结构之上

> [相关思维导图](https://gitee.com/gin9/MindMap)

## 相关书籍和资源
- 大话数据结构
- 算法图解
- 算法的乐趣

- 算法 [official site](https://algs4.cs.princeton.edu/home/)
- 算法导论(英文原版更好) 麻省理工有公开课
- 数据结构与算法分析 C C++ Java 三种语言版本
- 数据结构 严蔚敏
- 数据结构与算法解析  高一凡

- 剑指Offer
- 编程珠玑 对大量数据问题的算法研究
- 编程之美 微软面试官所著,难度较高

- 计算机程序设计艺术
- 算法帝国
- 数学之美
- 算法之美

> [王争的课程对应源码](https://github.com/wangzheng0822/algo)`这里主要也是他的课程内容`
> [Github:TheAlgorithms](https://github.com/TheAlgorithms) `有各种编程语言的算法实现`
> [《编程之法》](https://github.com/julycoding/The-Art-Of-Programming-By-July)

> [清华大学 邓俊辉 数据结构 C++实现](https://dsa.cs.tsinghua.edu.cn/~deng/ds/dsacpp/index.htm)

> [DataStructures.pdf](http://www-bcf.usc.edu/~dkempe/teaching/DataStructures.pdf)
> [notes.pdf](http://www.cs.yale.edu/homes/aspnes/classes/223/notes.pdf)
> [notes](http://web.stanford.edu/class/archive/cs/cs103/cs103.1164/notes/)
> [data structures.pdf](https://inst.eecs.berkeley.edu/~cs61b/fa18/materials/book2/data-structures.pdf)
> [Data structure.pdf](https://www.cs.auckland.ac.nz/textbookCS220/ebook/DGW2.pdf)
> [algorithms](http://jeffe.cs.illinois.edu/teaching/algorithms/)

**********************

离散数学基础: 集合、偏序集、良序、数学归纳法、级数、递归、递推 
概率基础: 随机分布、概率、伯努利实验、数学期望、期望值的线性率

- 常用数据结构:
    - 数组、链表、栈、队列、散列表、二叉树、堆、跳表、图、Trie树
- 常用算法  
    - 递归、排序、二分查找、搜索、哈希算法、贪心算法、分治算法、回溯算法、动态规划、字符串匹配算法。

*******************

## 基础概念
### 时间复杂度
> [Java中的实践](http://www.baeldung.com/java-algorithm-complexity)

所有代码的执行时间 T(n) 与每行代码的执行次数 n 成正比。

- T(n) = O(f(n))
    - T(n) 表示代码执行的时间；
    - n 表示数据规模的大小；
    - f(n) 表示每行代码执行的次数总和。

因为这是一个公式，所以用 f(n) 来表示。公式中的 O，表示代码的执行时间 T(n) 与 f(n) 表达式成正比。

大 O 时间复杂度实际上并不具体表示代码真正的执行时间，而是表示代码执行时间随数据规模增长的变化趋势，所以，也叫作渐进时间复杂度(asymptotic time complexity) 简称时间复杂度

#### 时间复杂度分析
1. 只关注循环执行次数最多的代码
1. 加法原则: 相加时的结果是: 总复杂度等于量级最大的那段代码的复杂度
1. 乘法原则: 嵌套代码的复杂度等于嵌套内外代码复杂度的乘积

- 常见的时间复杂度
    - 常量阶 O(1)
    - 对数阶 O(log n)
    - 线性阶 O(n)
    - 线性对数阶 O(n log n)
    - 平方阶 O(n^2) 立方阶O(n^3 )  k次方阶 O(n^k) `用 ^ 表示次方`
    - 指数阶 O(2^n)
    - 阶乘阶 O(n!)

> O(1)

一般情况下，只要算法中不存在循环语句、递归语句，即使有成千上万行的代码，其时间复杂度也是Ο(1)

> O(logn)、O(nlogn)

```c
    int i=1;
    while (i <= n)  {
        i = i * 3;
    }
```
对数之间是可以互相转换的，log3n 就等于 log32 * log2n，所以 O(log3n) = O(C * log2n)，其中 C=log32 是一个常量。  
基于我们前面的一个理论：在采用大 O 标记复杂度的时候，可以忽略系数，即 O(Cf(n)) = O(f(n))  
所以，O(log2n) 就等于 O(log3n)。因此，在对数阶时间复杂度的表示方法里，我们忽略对数的“底”，统一表示为 O(logn)。  

O(nlogn) 也是一种非常常见的算法时间复杂度。比如，归并排序、快速排序的时间复杂度都是 O(nlogn)。

个人看法: 当循环中的循环变量的增长是以指数形式增长, 从而达到循环退出条件, 那么时间复杂度就是对数形式的

>  O(m+n)、O(m*n)

时间复杂度由两个数据的规模来决定, 原来的加法法则需要改为 T1(m) + T2(n) = O(f(m) + g(n)), 不清楚 m n 大小关系, 所以只能同时评估


四个复杂度分析方面的知识点，最好情况时间复杂度（best case time complexity）、最坏情况时间复杂度（worst case time complexity）、平均情况时间复杂度（average case time complexity）、均摊时间复杂度（amortized time complexity）。

为了表示代码在不同情况下的不同时间复杂度，我们需要引入三个概念：最好情况时间复杂度，最坏情况时间复杂度和平均情况时间复杂度  

#### 最好最坏时间复杂度
```c
    // n 表示数组 array 的长度
    int find(int[] array, int n, int x) {
    int i = 0;
    int pos = -1;
    for (; i < n; ++i) {
        if (array[i] == x) pos = i;
    }
    return pos;
    }
```
顾名思义，最好情况时间复杂度就是，在最理想的情况下，执行这段代码的时间复杂度。就像我们刚刚讲到的，在最理想的情况下，要查找的变量x正好是数组的第一个元素，这个时候对应的时间复杂度就是最好情况时间复杂度 O(1)。  
同理，最坏情况时间复杂度就是，在最糟糕的情况下，执行这段代码的时间复杂度。就像刚举的那个例子，如果数组中没有要查找的变量x，我们需要把整个数组都遍历一遍才行，所以这种最糟糕情况下对应的时间复杂度就是最坏情况时间复杂度 O(n)。  

#### 平均时间复杂度
要查找的变量 x 在数组中的位置，有 n+1 种情况：`在数组的 0～n-1 位置中和不在数组中`。我们把每种情况下，查找需要遍历的元素个数累加起来，然后再除以 n+1，就可以得到需要遍历的元素个数的平均值

> (1+2+3+...+n+n) / (n+1) = n(n+3) / 2(n+1)

时间复杂度的大 O 标记法中，可以省略掉系数、低阶、常量，所以，咱们把刚刚这个公式简化之后，得到的平均时间复杂度就是 O(n)。

我们知道，要查找的变量 x，要么在数组里，要么就不在数组里。这两种情况对应的概率统计起来很麻烦，为了方便, 假设在数组中与不在数组中的概率都为 1/2。  
另外，要查找的数据出现在 0～n-1 这 n 个位置的概率也是一样的，为 1/n。  
所以，根据概率乘法法则，要查找的数据出现在 0～n-1 中任意位置的概率就是 1/(2n)。   
因此，前面的推导过程中存在的最大问题就是，没有将各种情况发生的概率考虑进去。如果我们把每种情况发生的概率也考虑进去，那平均时间复杂度的计算过程就变成了这样：  

> 1 * 1/2n + 2 * 1/2n + n * 1/2n + 1/2 * n = (3n+1)/4

这个值就是概率论中的`加权平均值`，也叫作`期望值`，所以平均时间复杂度的全称应该叫`加权平均时间复杂度`或者`期望时间复杂度`。  
引入概率之后，前面那段代码的加权平均值为 (3n+1)/4。用大 O 表示法来表示，去掉系数和常量，这段代码的加权平均时间复杂度仍然是 O(n)。  
你可能会说，平均时间复杂度分析好复杂啊，还要涉及概率论的知识。实际上，在大多数情况下，我们并不需要区分最好、最坏、平均情况时间复杂度三种情况。  
很多时候，我们使用一个复杂度就可以满足需求了。只有同一块代码在不同的情况下，时间复杂度有量级的差距，我们才会使用这三种复杂度表示法来区分。

#### 均摊时间复杂度

```c
    // array 表示一个长度为 n 的数组
    // 代码中的 array.length 就等于 n
    int[] array = new int[n];
    int count = 0;
    
    void insert(int val) {
        if (count == array.length) {
        int sum = 0;
        for (int i = 0; i < array.length; ++i) {
            sum = sum + array[i];
        }
        array[0] = sum;
        count = 1;
        }

        array[count] = val;
        ++count;
    }
```
这段代码实现了一个往数组中插入数据的功能。当数组满了之后，也就是代码中的 count == array.length 时，我们用 for 循环遍历数组求和，并清空数组，  
将求和之后的 sum 值放到数组的第一个位置，然后再将新的数据插入。但如果数组一开始就有空闲空间，则直接将数据插入数组。

最理想的情况下，数组中有空闲空间，我们只需要将数据插入到数组下标为 count 的位置就可以了，所以最好情况时间复杂度为 O(1)。  
最坏的情况下，数组中没有空闲空间了，我们需要先做一次数组的遍历求和，然后再将数据插入，所以最坏情况时间复杂度为 O(n)。  
  
假设数组的长度是 n，根据数据插入的位置的不同，我们可以分为 n 种情况，每种情况的时间复杂度是 O(1)。  
除此之外，还有一种“额外”的情况，就是在数组没有空闲空间时插入一个数据，这个时候的时间复杂度是 O(n)。  
而且，这 n+1 种情况发生的概率一样，都是 1/(n+1)。所以，根据加权平均的计算方法，我们求得的平均时间复杂度就是  

> 1 * 1/(n+1) + 1 * 1/(n+1)+...+ n * 1/(n+1) = O(1)

首先，find() 函数在极端情况下，复杂度才为 O(1)。但 insert() 在大部分情况下，时间复杂度都为 O(1)。只有个别情况下，复杂度才比较高，为 O(n)。这是 insert()第一个区别于 find() 的地方。  
我们再来看第二个不同的地方。对于 insert() 函数来说，O(1) 时间复杂度的插入和 O(n) 时间复杂度的插入，出现的频率是非常有规律的，而且有一定的前后时序关系，一般都是一个 O(n) 插入之后，紧跟着 n-1 个 O(1) 的插入操作，循环往复。  

所以，针对这样一种特殊场景的复杂度分析，我们并不需要像之前讲平均复杂度分析方法那样，找出所有的输入情况及相应的发生概率，然后再计算加权平均值。  
针对这种特殊的场景，我们引入了一种更加简单的分析方法：摊还分析法，通过摊还分析得到的时间复杂度我们起了一个名字，叫均摊时间复杂度。  

对一个数据结构进行一组连续操作中，大部分情况下时间复杂度都很低，只有个别情况下时间复杂度比较高，而且这些操作之间存在前后连贯的时序关系，这个时候，我们就可以将这一组操作放在一块儿分析，看是否能将较高时间复杂度那次操作的耗时，平摊到其他那些时间复杂度比较低的操作上。而且，在能够应用均摊时间复杂度分析的场合，一般均摊时间复杂度就等于最好情况时间复杂度。  

均摊时间复杂度就是一种特殊的平均时间复杂度，我们没必要花太多精力去区分它们。你最应该掌握的是它的分析方法，摊还分析.

```C
    // 全局变量，大小为 10 的数组 array，长度 len，下标 i。
    int array[] = new int[10]; 
    int len = 10;
    int i = 0;

    // 往数组中添加一个元素
    void add(int element) {
        if (i >= len) { // 数组空间不够了
            // 重新申请一个 2 倍大小的数组空间
            int new_array[] = new int[len*2];
            // 把原来 array 数组中的数据依次 copy 到 new_array
            for (int j = 0; j < len; ++j) {
            new_array[j] = array[j];
            }
            // new_array 复制给 array，array 现在大小就是 2 倍 len 了
            array = new_array;
            len = 2 * len;
        }
        // 将 element 放到下标为 i 的位置，下标 i 加一
        array[i] = element;
        ++i;
    }
```
> 最好是O(1)，最差是O(n), 均摊是O(1)

************************

### 空间复杂度
类比一下，空间复杂度全称就是渐进空间复杂度（asymptotic space complexity），表示算法的存储空间与数据规模之间的增长关系。


## 基础数据结构
### 线性表
> 数组, 链表, 队列, 栈 

#### 数组
> 一组连续的内存空间,存放一组相同数据类型的数据

访问: 根据下标任意访问的时间复杂度为O（1）, 
插入: 从最好O(1) 最坏O(n) 平均O(n)
删除: 从最好O(1) 最坏O(n) 平均O(n)

多次删除集中在一起，提高删除效率
记录下已经被删除的数据，每次的删除操作并不是搬移数据，只是记录数据已经被删除，当数组没有更多的存储空间时，再触发一次真正的删除操作。即JVM标记清除垃圾回收算法。
```c
    int main(int argc, char* argv[]){
        int i = 0;
        int arr[3] = {0};
        for(; i<=3; i++){
            arr[i] = 0;
            printf("hello world\n");
        }
        return 0;
    }
```
> 以上代码会死循环执行, 栈设计采用小端模式的系统才会出现

例子中死循环的问题跟编译器分配内存和字节对齐有关 数组3个元素 加上一个变量a 。4个整数刚好能满足8字节对齐 所以i的地址恰好跟着a2后面 导致死循环  
如果数组长度为4 且循环5次 则这里不会出现死循环。因为编译器64位操作系统下 默认会进行8字节对齐 变量i的地址就不紧跟着数组后面了。

> 存疑1: 当长度为4 无法解释. 压栈顺序: i，a[2]，a[1]，a[0], 所以 a[3]访问到的是i   
> 存疑2: gcc有一个编译选项（-fno-stack-protector）用于关闭堆栈保护功能。默认情况下启动了堆栈保护，不管i声明在前还是在后，i都会在数组之后压栈，只会循环4次；如果关闭堆栈保护功能，则会出现死循环.

[参考 GCC编译器堆栈保护技术](https://www.ibm.com/developerworks/cn/linux/l-cn-gccstack/index.html)
[GCC 堆栈保护技术](https://firmianay.gitbooks.io/ctf-all-in-one/content/doc/4.4_gcc_sec.html)

**`容器和数组`**
> 众多语言都有对数组封装好的容器类

Java 中 ArrayList 和 数组的对比

优势
1. 对数组操作的细节进行封装, 
1. 支持动态扩容, 空间不够会扩容为原大小的1.5倍
劣势
1. ArrayList 无法存放基础数据类型, 只能用包装类型, 这样就涉及到了 自动拆装箱,影响性能
1. 表示二维结构数据时, 没有数组直观

> 最好在创建 ArrayList的时候设置好初始大小,避免不必要的数据搬运
对于业务开发，直接使用容器就足够了，省时省力。毕竟损耗一丢丢性能，完全不会影响到系统整体的性能。但如果你是做一些非常底层的开发，比如开发网络框架，性能的优化需要做到极致，这个时候数组就会优于容器，成为首选。

#### 链表
> 单链表 双向链表 循环链表

*****************

分治算法
动态规划 最值 极值
不直接找问题, 而是根据你的输入, 和答案之前关系的规律

柯里化, continuation 高阶函数, 尾递归

*********************
## 匹配算法
- [字符串相似度匹配](http://zjwyhll.blog.163.com/blog/static/75149781201281142630851/)

## 排序算法
> [参考博客: 九种排序算法的可视化及比较](https://zhuanlan.zhihu.com/p/34421623?group_id=955945213303250944)

*********
# 密码学

## Diffie-Hellman Key Exchange算法
> Whitfield Diffie 和 Martin Hellman ，他们于２０１５年获得了计算机科学领域的最高奖：图灵奖

![码农翻身](https://raw.githubusercontent.com/Kuangcp/ImageRepos/master/Tech/arithmetic/Diffie-HellmanKeyExchange.png)

`最后神奇的魔法发生了， 我们两个得到了同样的值 s = 10！`
-  这个s 的值只有我们两个才知道，  其实就是密钥了， 可以用来做加密解密了（ 当然，这只是一个例子，实际的密钥不会这么短）， 我们俩的通讯从此就安全了。
    -  “数学家小帅哥说了， 原因很简单，(gｘ mod p)ｙ mod p　和　(gｙ mod p)ｘ mod p　是相等的！ ”
    -  “那黑客不能从公开传输的 p = 17, g = 3, a = 6 , b = 12 推算出s = 10 吗？” 我问道。
    -  “当然不能， 不过前提是需要使用非常大的p , x, y,  这样以来，即使黑客动用地球上所有的计算资源， 也推算不出来。 ”

# 实际问题
例如存储一个部门关系, 上下级, 以及同级要有序, 并且, 这个关系树是能随意调整结构的, 每个节点和节点之间任意断开和连接

name/id, parent, index



